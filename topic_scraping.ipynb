{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "dfb7641c-3c0a-4ed9-b78b-064001b5fea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "97687abc-63dc-4253-8e21-fa6fa2832348",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://github.com/topics/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf3459ce-3268-4be6-8933-363eeccecf06",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac1501de-8891-466b-b2ef-b497a8febfa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2dedf566-1592-4143-90f7-380b8482a805",
   "metadata": {},
   "outputs": [],
   "source": [
    "page_contents = response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eb71c6cd-8612-4259-be22-124749bd419b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('webpage.html', 'w',  encoding=\"utf-8\") as f:\n",
    "    f.write(page_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "553acc0f-ab95-471b-912b-60222c3f271a",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = BeautifulSoup(page_contents, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e6c1f5a6-f65b-4e66-a7af-42b61cbb82cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "c1aed73b-a211-4a01-8a24-7c1d86eabfef",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_doc = BeautifulSoup(response_url.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "73784520-7cb9-473d-a335-70a5bd5ef91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def star_count(stars_str):\n",
    "    stars_str = stars_str.strip()\n",
    "\n",
    "    if stars_str[-1] == 'k':\n",
    "       return int(float(stars_str[:-1]) * 100)\n",
    "    return int(stars_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905fcb5c-c807-41f4-b942-36b97b385884",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GET ALL INFO ABOUT ALL REPOSITORY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "a40fdbc7-cc13-4aa7-9e76-013ea5940555",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "30d402ca-7f33-4eb1-81cf-b5f9699055c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topic_page(topic_urls):\n",
    "    response = requests.get(topic_urls)\n",
    "    if response.status_code != 200:\n",
    "        raise Exception('Failed to get data...'.format(topic_url))\n",
    "\n",
    "    topic_doc = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    return topic_doc\n",
    "\n",
    "def get_repo_info(h_tags, star_tags):\n",
    "    a_tags = h_tags.find_all('a')\n",
    "    username = a_tags[0].text.strip()\n",
    "    repo_name = a_tags[1].text.strip()\n",
    "    repo_url = 'https://gtihub.com' + a_tags[1]['href']\n",
    "    sts = star_count(star_tags.text)\n",
    "\n",
    "    return username, repo_name,sts, repo_url\n",
    "\n",
    "def get_topic_repo(topic_doc):\n",
    "    \n",
    "    h1_class_select = \"f3 color-fg-muted text-normal lh-condensed\"\n",
    "    h_tags = topic_doc.find_all('h3', {'class' : h1_class_select})\n",
    "    \n",
    "    star_tags = topic_doc.find_all('span',{'id':\"repo-stars-counter-star\"})\n",
    "    \n",
    "    #get all info\n",
    "    \n",
    "    topic_repo_dict = {\n",
    "        'username': [],\n",
    "        'repo_name':[],\n",
    "        'stars':[],\n",
    "        'repo_url':[]\n",
    "    }\n",
    "\n",
    "    for i in range( len(h_tags)):\n",
    "        repo_info  = get_repo_info(h_tags[i], star_tags[i])\n",
    "    \n",
    "        topic_repo_dict['username'].append(repo_info[0])\n",
    "        topic_repo_dict['repo_name'].append(repo_info[1])\n",
    "        topic_repo_dict['stars'].append(repo_info[2])\n",
    "        topic_repo_dict['repo_url'].append(repo_info[3])\n",
    "\n",
    "    return pd.DataFrame(topic_repo_dict)\n",
    "\n",
    "def scrape_topic(topic_url, topic_name):\n",
    "    fileName = topic_name + '.csv'\n",
    "    if os.path.exists(fileName):\n",
    "        print(\"The file {} already exists..\".format(fileName))\n",
    "        return\n",
    "    \n",
    "    topic_df = get_topic_repo(get_topic_page(topic_url))\n",
    "    topic_df.to_csv(fileName + '.csv', index= None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "a4a6b981-528b-4974-9165-9fdd399df2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tittle(doc):\n",
    "        selection_class = 'f3 lh-condensed mb-0 mt-1 Link--primary'\n",
    "        topic_title_tags= doc.find_all('p',{'class' : selection_class})\n",
    "        topic_titles = []\n",
    "    \n",
    "        for tag in topic_title_tags:\n",
    "            topic_titles.append(tag.text)\n",
    "        return topic_titles\n",
    "\n",
    "def get_desc(doc):\n",
    "        desc_selection_class = 'f5 color-fg-muted mb-0 mt-1'\n",
    "        topics_desc_tags= doc.find_all('p',{'class' : desc_selection_class})\n",
    "        \n",
    "        topics_desc = []\n",
    "        \n",
    "        for tag in topics_desc_tags:\n",
    "            topics_desc.append(tag.text.strip())\n",
    "        return topics_desc\n",
    "\n",
    "def get_topics_urls(doc):\n",
    "        topic_links_tags = doc.find_all('a', {'class' : \"no-underline flex-grow-0\"})\n",
    "        topic_urls = []\n",
    "        \n",
    "        for tags in topic_links_tags:\n",
    "            topic_urls.append('https://github.com/' + tags['href'])\n",
    "        return topic_urls\n",
    "\n",
    "def scrape_topics():\n",
    "    topics_url = \"https://github.com/topics\"\n",
    "    respone = requests.get(topics_url)\n",
    "    if response.status_code != 200:\n",
    "        raise Exception('Failed to get data...'.format(topic_url))\n",
    "\n",
    "    topics_dict = { \n",
    "        'title': get_tittle(doc), \n",
    "        'description': get_desc(doc),\n",
    "        'url': get_topics_urls(doc)\n",
    "    }\n",
    "    return pd.DataFrame(topics_dict)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "dbf2c05b-f587-4aed-8042-dd7f75f67b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_topics_repo():\n",
    "    print(\"Scrapeing.. topics list\")\n",
    "    topics_df= scrape_topics()\n",
    "\n",
    "    for index ,row in topics_df.iterrows():\n",
    "        print('Scrapping all repositories in the topic \"{}\"'.format(row['title']))\n",
    "        scrape_topic(row['url'],row['title'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "1fd099cb-5da4-4392-9445-e8a2f8e9fbbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scrapeing.. topics list\n",
      "Scrapping all repositories in the topic \"Awesome Lists\"\n",
      "Scrapping all repositories in the topic \"Chrome\"\n",
      "Scrapping all repositories in the topic \"Code quality\"\n",
      "Scrapping all repositories in the topic \"Compiler\"\n",
      "Scrapping all repositories in the topic \"CSS\"\n",
      "Scrapping all repositories in the topic \"Database\"\n",
      "Scrapping all repositories in the topic \"Front end\"\n",
      "Scrapping all repositories in the topic \"JavaScript\"\n",
      "Scrapping all repositories in the topic \"Node.js\"\n",
      "Scrapping all repositories in the topic \"npm\"\n",
      "Scrapping all repositories in the topic \"Project management\"\n",
      "Scrapping all repositories in the topic \"Python\"\n",
      "Scrapping all repositories in the topic \"React\"\n",
      "Scrapping all repositories in the topic \"React Native\"\n",
      "Scrapping all repositories in the topic \"Scala\"\n",
      "Scrapping all repositories in the topic \"TypeScript\"\n"
     ]
    }
   ],
   "source": [
    "scrape_topics_repo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4568dc-2a35-4cf0-a759-764e77ed90bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
